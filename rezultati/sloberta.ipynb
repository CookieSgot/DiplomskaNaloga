{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gasper\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gasper\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 2862/2862 [00:00<00:00, 9631.37 examples/s]\n",
      "Map: 100%|██████████| 3000/3000 [00:00<00:00, 10323.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('../data/headlines_test.csv')#.sample(10, random_state=42)\n",
    "test2 = pd.read_csv('../data/reddit_test.csv')\n",
    "\n",
    "dataset = ds.DatasetDict({\n",
    "    \"test\": ds.Dataset.from_pandas(test),\n",
    "    \"test2\":ds.Dataset.from_pandas(test2)\n",
    "})\n",
    "\n",
    "modelname = \"EMBEDDIA/sloberta\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=160, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines model na headlines testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../training/sloberta_headlines\")\n",
    "pipe = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "predictions = pipe(dataset[\"test\"][\"text\"])\n",
    "prediction = [int(pred['label'].split('_')[-1]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.3272066329827235\n",
      "Accuracy: 0.8522012578616353\n",
      "Precision: 0.8787638668779715\n",
      "Recall: 0.8042059463379261\n",
      "f1 score: 0.8398333964407422\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.703128\n",
      "ROC AUC: 0.850518\n",
      "[[1330  153]\n",
      " [ 270 1109]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kontekst podmnožica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.604365338911715\n",
      "Accuracy: 0.9\n",
      "Precision: 0.9285714285714286\n",
      "Recall: 0.8666666666666667\n",
      "f1 score: 0.896551724137931\n"
     ]
    }
   ],
   "source": [
    "positive_in = test[test['label'] == 1].sample(15, random_state=42).index\n",
    "negative_in = test[test['label'] == 0].sample(15, random_state=42).index\n",
    "\n",
    "c = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "a = [prediction[i] for i in positive_in]\n",
    "b = [prediction[i] for i in negative_in]\n",
    "d = a + b\n",
    "\n",
    "recall = metrics.recall_score(c,d)\n",
    "precision = metrics.precision_score(c,d)\n",
    "f1_score = metrics.f1_score(c,d)\n",
    "accuracy = metrics.accuracy_score(c,d)\n",
    "loss = metrics.log_loss(c,d)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines model na reddit testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe(dataset[\"test2\"][\"text\"])\n",
    "prediction = [int(pred['label'].split('_')[-1]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 18.09391400133681\n",
      "Accuracy: 0.498\n",
      "Precision: 0.5069582504970179\n",
      "Recall: 0.16853932584269662\n",
      "f1 score: 0.25297619047619047\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test2\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.001750\n",
      "ROC AUC: 0.500880\n",
      "[[1239  248]\n",
      " [1258  255]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test2\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit model na reddit testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../training/sloberta_reddit\")\n",
    "pipe = pipeline(task=\"text-classification\", model=model, tokenizer=tokenizer, device=\"cuda\")\n",
    "predictions = pipe(dataset[\"test2\"][\"text\"])\n",
    "prediction = [int(pred['label'].split('_')[-1]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 10.80108146560544\n",
      "Accuracy: 0.7003333333333334\n",
      "Precision: 0.7114325068870524\n",
      "Recall: 0.6827495042961005\n",
      "f1 score: 0.6967959527824621\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test2\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.400833\n",
      "ROC AUC: 0.700487\n",
      "[[1068  419]\n",
      " [ 480 1033]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test2\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kontekst podmnožica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 8.410185790794003\n",
      "Accuracy: 0.7666666666666667\n",
      "Precision: 0.7857142857142857\n",
      "Recall: 0.7333333333333333\n",
      "f1 score: 0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "positive_in = test2[test2['label'] == 1].sample(15, random_state=42).index\n",
    "negative_in = test2[test2['label'] == 0].sample(15, random_state=42).index\n",
    "\n",
    "c = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "a = [prediction[i] for i in positive_in]\n",
    "b = [prediction[i] for i in negative_in]\n",
    "d = a + b\n",
    "\n",
    "recall = metrics.recall_score(c,d)\n",
    "precision = metrics.precision_score(c,d)\n",
    "f1_score = metrics.f1_score(c,d)\n",
    "accuracy = metrics.accuracy_score(c,d)\n",
    "loss = metrics.log_loss(c,d)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit model na headlines testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe(dataset[\"test\"][\"text\"])\n",
    "prediction = [int(pred['label'].split('_')[-1]) for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 18.96636687771154\n",
      "Accuracy: 0.47379454926624737\n",
      "Precision: 0.449802371541502\n",
      "Recall: 0.4126178390137781\n",
      "f1 score: 0.43040847201210286\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: -0.056866\n",
      "ROC AUC: 0.471649\n",
      "[[787 696]\n",
      " [810 569]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

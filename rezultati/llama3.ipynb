{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, BitsAndBytesConfig, Trainer\n",
    "from transformers import pipeline\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import datasets as ds\n",
    "from peft import PeftModel\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c9f2112af54e128ddc36359903c3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2862 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9576d886589d4c7d8a558a632f90661f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/headlines_test.csv')\n",
    "test2 = pd.read_csv('../data/reddit_test.csv')\n",
    "\n",
    "dataset = ds.DatasetDict({\n",
    "    \"test\": ds.Dataset.from_pandas(test),\n",
    "    \"test2\":ds.Dataset.from_pandas(test2)\n",
    "})\n",
    "\n",
    "modelname = \"../../Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", max_length=160, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines model na headlines testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550096339af24e7d9f8bb701d604b292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ../../Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit = True\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"../training/llama3_headlines\", quantization_config=quantization_config)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "prediction = np.argmax(predictions.predictions, axis=-1)\n",
    "prediction = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.871402156785014\n",
      "Accuracy: 0.9203354297693921\n",
      "Precision: 0.9356548069644209\n",
      "Recall: 0.896301667875272\n",
      "f1 score: 0.9155555555555556\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.840225\n",
      "ROC AUC: 0.919493\n",
      "[[1398   85]\n",
      " [ 143 1236]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Headlines model na reddit testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset=tokenized_datasets[\"test2\"])\n",
    "prediction = np.argmax(predictions.predictions, axis=-1)\n",
    "prediction = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 17.829593876483283\n",
      "Accuracy: 0.5053333333333333\n",
      "Precision: 0.5206258890469416\n",
      "Recall: 0.2419035029742234\n",
      "f1 score: 0.3303249097472924\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test2\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.015202\n",
      "ROC AUC: 0.507636\n",
      "[[1150  337]\n",
      " [1147  366]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test2\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit model na reddit testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d838cbe6f54a4da08c15494002907ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at ../../Meta-Llama-3-8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"../training/llama3_reddit\", quantization_config=quantization_config)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(test_dataset=tokenized_datasets[\"test2\"])\n",
    "prediction = np.argmax(predictions.predictions, axis=-1)\n",
    "prediction = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.719771863931927\n",
      "Accuracy: 0.7303333333333333\n",
      "Precision: 0.7699386503067485\n",
      "Recall: 0.6635822868473232\n",
      "f1 score: 0.7128150514731985\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test2\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: 0.461277\n",
      "ROC AUC: 0.730917\n",
      "[[1187  300]\n",
      " [ 509 1004]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test2\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test2\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit model na headlines testih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(test_dataset=tokenized_datasets[\"test\"])\n",
    "prediction = np.argmax(predictions.predictions, axis=-1)\n",
    "prediction = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 18.575956935341647\n",
      "Accuracy: 0.48462613556953177\n",
      "Precision: 0.45102040816326533\n",
      "Recall: 0.3205221174764322\n",
      "f1 score: 0.37473505722763883\n"
     ]
    }
   ],
   "source": [
    "recall = metrics.recall_score(dataset[\"test\"][\"label\"],prediction)\n",
    "precision = metrics.precision_score(dataset[\"test\"][\"label\"],prediction)\n",
    "f1_score = metrics.f1_score(dataset[\"test\"][\"label\"],prediction)\n",
    "accuracy = metrics.accuracy_score(dataset[\"test\"][\"label\"],prediction)\n",
    "loss = metrics.log_loss(dataset[\"test\"][\"label\"],prediction)\n",
    "\n",
    "print('Loss:',loss)\n",
    "print('Accuracy:',accuracy)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('f1 score:',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens kappa: -0.042689\n",
      "ROC AUC: 0.478872\n",
      "[[945 538]\n",
      " [937 442]]\n"
     ]
    }
   ],
   "source": [
    "kappa = metrics.cohen_kappa_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "auc = metrics.roc_auc_score(dataset[\"test\"][\"label\"],prediction)\n",
    "print('ROC AUC: %f' % auc)\n",
    "matrix = metrics.confusion_matrix(dataset[\"test\"][\"label\"],prediction)\n",
    "print(matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
